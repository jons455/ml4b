{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alexkroeker/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hdbscan in /Users/alexkroeker/opt/anaconda3/lib/python3.8/site-packages (0.8.27)\n",
      "Requirement already satisfied: scipy>=1.0 in /Users/alexkroeker/opt/anaconda3/lib/python3.8/site-packages (from hdbscan) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in /Users/alexkroeker/opt/anaconda3/lib/python3.8/site-packages (from hdbscan) (0.23.2)\n",
      "Requirement already satisfied: joblib>=1.0 in /Users/alexkroeker/opt/anaconda3/lib/python3.8/site-packages (from hdbscan) (1.0.1)\n",
      "Requirement already satisfied: six in /Users/alexkroeker/opt/anaconda3/lib/python3.8/site-packages (from hdbscan) (1.15.0)\n",
      "Requirement already satisfied: cython>=0.27 in /Users/alexkroeker/opt/anaconda3/lib/python3.8/site-packages (from hdbscan) (0.29.21)\n",
      "Requirement already satisfied: numpy>=1.16 in /Users/alexkroeker/opt/anaconda3/lib/python3.8/site-packages (from hdbscan) (1.19.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/alexkroeker/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.20->hdbscan) (2.1.0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-00ec57a6a3d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdatax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install hdbscan'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhdbscan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hdbscan/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhdbscan_\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHDBSCAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdbscan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrobust_single_linkage_\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRobustSingleLinkage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrobust_single_linkage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvalidity\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidity_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m from .prediction import (approximate_predict,\n\u001b[1;32m      5\u001b[0m                          \u001b[0mmembership_vector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hdbscan/hdbscan_.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m from ._hdbscan_linkage import (single_linkage,\n\u001b[0m\u001b[1;32m     22\u001b[0m                                \u001b[0mmst_linkage_core\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                \u001b[0mmst_linkage_core_vector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mhdbscan/_hdbscan_linkage.pyx\u001b[0m in \u001b[0;36minit hdbscan._hdbscan_linkage\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import KMeans\n",
    "import re\n",
    "import preprocessor as p#forming a separate feature for cleaned tweets\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import seaborn as sns\n",
    "import sklearn.datasets as datax\n",
    "!pip install hdbscan\n",
    "import hdbscan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "sns.set_color_codes()\n",
    "plot_kwds = {'alpha' : 0.5, 's' : 80, 'linewidths':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_twin_tweets_data = []\n",
    "cyber_twin_tweets_data = []\n",
    "device_shadow_data = []\n",
    "digital_counterpart_data = []\n",
    "digital_master_data = []\n",
    "digital_model_data = []\n",
    "digital_repliica_data = []\n",
    "digital_shadow_data = []\n",
    "digital_thread_data = []\n",
    "information_mirroring_data = []\n",
    "product_agent_data = []\n",
    "product_avatar_data = []\n",
    "product_shadow_data = []\n",
    "virtual_twin_data = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = [] #list_of_tweets_data_lists\n",
    "alldata.append(digital_twin_tweets_data)\n",
    "alldata.append(cyber_twin_tweets_data)\n",
    "alldata.append(device_shadow_data)\n",
    "alldata.append(digital_counterpart_data)\n",
    "alldata.append(digital_master_data)\n",
    "alldata.append(digital_model_data)\n",
    "alldata.append(digital_repliica_data)\n",
    "alldata.append(digital_shadow_data)\n",
    "alldata.append(digital_thread_data)\n",
    "alldata.append(information_mirroring_data)\n",
    "alldata.append(product_agent_data)\n",
    "alldata.append(product_avatar_data)\n",
    "alldata.append(product_shadow_data)\n",
    "alldata.append(virtual_twin_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], [], [], [], [], [], [], [], [], [], [], [], []]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in range(14):\n",
    "    digital_twin_tweets_data.append(open('Tweet-Data/digital_twin_tweets-'+str(2007+file)+'.jl'))\n",
    "for file in range(14):\n",
    "    cyber_twin_tweets_data.append(open('Tweet-Data/Cyber_Twin_tweets-'+str(2007+file)+'.jl')) \n",
    "for file in range(14):\n",
    "    device_shadow_data.append(open('Tweet-Data/Device_Shadow_tweets-'+str(2007+file)+'.jl')) \n",
    "for file in range(14):\n",
    "    digital_counterpart_data.append(open('Tweet-Data/Digital_Counterpart_tweets-'+str(2007+file)+'.jl')) \n",
    "for file in range(14):\n",
    "    digital_master_data.append(open('Tweet-Data/Digital_Master_tweets-'+str(2007+file)+'.jl')) \n",
    "for file in range(14):\n",
    "    digital_model_data.append(open('Tweet-Data/Digital_Model_tweets-'+str(2007+file)+'.jl')) \n",
    "for file in range(14):\n",
    "    digital_repliica_data.append(open('Tweet-Data/Digital_Replica_tweets-'+str(2007+file)+'.jl')) \n",
    "for file in range(14):\n",
    "    digital_shadow_data.append(open('Tweet-Data/digital_shadow_tweets-'+str(2007+file)+'.jl')) \n",
    "for file in range(14):\n",
    "    digital_thread_data.append(open('Tweet-Data/Digital_Thread_tweets-'+str(2007+file)+'.jl')) \n",
    "for file in range(14):\n",
    "    information_mirroring_data.append(open('Tweet-Data/Information_Mirroring_Model_tweets-'+str(2007+file)+'.jl'))\n",
    "for file in range(14):\n",
    "    product_agent_data.append(open('Tweet-Data/Product_Agent_tweets-'+str(2007+file)+'.jl')) \n",
    "for file in range(14):\n",
    "    product_avatar_data.append(open('Tweet-Data/Product_Avatar_tweets-'+str(2007+file)+'.jl')) \n",
    "for file in range(14):\n",
    "    product_shadow_data.append(open('Tweet-Data/Product_Shadow_tweets-'+str(2007+file)+'.jl')) \n",
    "for file in range(14):\n",
    "    virtual_twin_data.append(open('Tweet-Data/Virtual_Twin_tweets-'+str(2007+file)+'.jl')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for obj in alldata:\n",
    "    print(len(obj))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_twin_tweets_list = []\n",
    "cyber_twin_tweets_list = []\n",
    "device_shadow_list = []\n",
    "digital_counterpart_list = []\n",
    "digital_master_list = []\n",
    "digital_model_list = []\n",
    "digital_repliica_list = []\n",
    "digital_shadow_list = []\n",
    "digital_thread_list = []\n",
    "information_mirroring_list = []\n",
    "product_agent_list = []\n",
    "product_avatar_list = []\n",
    "product_shadow_list = []\n",
    "virtual_twin_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in digital_twin_tweets_data:\n",
    "    for line in file:\n",
    "        digital_twin_tweets_list.append(json.loads(line))\n",
    "for file in cyber_twin_tweets_data:\n",
    "    for line in file:\n",
    "        cyber_twin_tweets_list.append(json.loads(line))\n",
    "for file in device_shadow_data:\n",
    "    for line in file:\n",
    "        device_shadow_list.append(json.loads(line))\n",
    "for file in digital_counterpart_data:\n",
    "    for line in file:\n",
    "        digital_counterpart_list.append(json.loads(line))\n",
    "for file in digital_master_data:\n",
    "    for line in file:\n",
    "        digital_master_list.append(json.loads(line))\n",
    "for file in digital_model_data:\n",
    "    for line in file:\n",
    "        digital_model_list.append(json.loads(line))\n",
    "for file in digital_repliica_data:\n",
    "    for line in file:\n",
    "        digital_repliica_list.append(json.loads(line))\n",
    "for file in digital_shadow_data:\n",
    "    for line in file:\n",
    "        digital_shadow_list.append(json.loads(line))\n",
    "for file in digital_thread_data:\n",
    "    for line in file:\n",
    "        digital_thread_list.append(json.loads(line))\n",
    "for file in information_mirroring_data:\n",
    "    for line in file:\n",
    "        information_mirroring_list.append(json.loads(line))\n",
    "for file in product_agent_data:\n",
    "    for line in file:\n",
    "        product_agent_list.append(json.loads(line))\n",
    "for file in product_avatar_data:\n",
    "    for line in file:\n",
    "        product_avatar_list.append(json.loads(line))\n",
    "for file in product_shadow_data:\n",
    "    for line in file:\n",
    "        product_shadow_list.append(json.loads(line))\n",
    "for file in virtual_twin_data:\n",
    "    for line in file:\n",
    "        virtual_twin_list.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "allLists = [] #list_of_tweets_data_lists\n",
    "allLists.append(digital_twin_tweets_list)\n",
    "allLists.append(cyber_twin_tweets_list)\n",
    "allLists.append(device_shadow_list)\n",
    "allLists.append(digital_counterpart_list)\n",
    "allLists.append(digital_master_list)\n",
    "allLists.append(digital_model_list)\n",
    "allLists.append(digital_repliica_list)\n",
    "allLists.append(digital_shadow_list)\n",
    "allLists.append(digital_thread_list)\n",
    "allLists.append(information_mirroring_list)\n",
    "allLists.append(product_agent_list)\n",
    "allLists.append(product_avatar_list)\n",
    "allLists.append(product_shadow_list)\n",
    "allLists.append(virtual_twin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "908\n",
      "16\n",
      "14\n",
      "22\n",
      "116\n",
      "157\n",
      "44\n",
      "87\n",
      "475\n",
      "14\n",
      "22\n",
      "16\n",
      "31\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "for list in allLists:\n",
    "    print(len(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(dictionary):\n",
    "    if dictionary['result_count'] == 0: return False\n",
    "    else: return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(digital_twin_tweets_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_twin_tweets_res = []\n",
    "cyber_twin_tweets_res = []\n",
    "device_shadow_res = []\n",
    "digital_counterpart_res = []\n",
    "digital_master_res = []\n",
    "digital_model_res = []\n",
    "digital_repliica_res = []\n",
    "digital_shadow_res = []\n",
    "digital_thread_res = []\n",
    "information_mirroring_res = []\n",
    "product_agent_res = []\n",
    "product_avatar_res = []\n",
    "product_shadow_res = []\n",
    "virtual_twin_res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dict in digital_twin_tweets_list:\n",
    "    digital_twin_tweets_res.append(dict['response'])\n",
    "for dict in cyber_twin_tweets_list:\n",
    "    cyber_twin_tweets_res.append(dict['response'])\n",
    "for dict in device_shadow_list:\n",
    "    device_shadow_res.append(dict['response'])\n",
    "for dict in digital_counterpart_list:\n",
    "    digital_counterpart_res.append(dict['response'])\n",
    "for dict in digital_master_list:\n",
    "    digital_master_res.append(dict['response'])\n",
    "for dict in digital_model_list:\n",
    "    digital_model_res.append(dict['response'])\n",
    "for dict in digital_repliica_list:\n",
    "    digital_repliica_res.append(dict['response'])\n",
    "for dict in digital_shadow_list:\n",
    "    digital_shadow_res.append(dict['response'])\n",
    "for dict in digital_thread_list:\n",
    "    digital_thread_res.append(dict['response'])\n",
    "for dict in information_mirroring_list:\n",
    "    information_mirroring_res.append(dict['response'])\n",
    "for dict in product_agent_list:\n",
    "    product_agent_res.append(dict['response'])\n",
    "for dict in product_avatar_list:\n",
    "    product_avatar_res.append(dict['response'])\n",
    "for dict in product_shadow_list:\n",
    "    product_shadow_res.append(dict['response'])\n",
    "for dict in virtual_twin_list:\n",
    "    virtual_twin_res.append(dict['response'])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'includes', 'meta'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digital_twin_tweets_res[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_twin_tweets_data = []\n",
    "cyber_twin_tweets_data = []\n",
    "device_shadow_data = []\n",
    "digital_counterpart_data = []\n",
    "digital_master_data = []\n",
    "digital_model_data = []\n",
    "digital_repliica_data = []\n",
    "digital_shadow_data = []\n",
    "digital_thread_data = []\n",
    "information_mirroring_data = []\n",
    "product_agent_data = []\n",
    "product_avatar_data = []\n",
    "product_shadow_data = []\n",
    "virtual_twin_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "908"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digital_twin_tweets_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dict in digital_twin_tweets_res:\n",
    "    if check(dict['meta']): digital_twin_tweets_data.append(dict['data'])\n",
    "for dict in cyber_twin_tweets_res:\n",
    "    cyber_twin_tweets_data.append(dict['data'])\n",
    "for dict in device_shadow_res:\n",
    "     if check(dict['meta']):device_shadow_data.append(dict['data'])\n",
    "for dict in digital_counterpart_res:\n",
    "    digital_counterpart_data.append(dict['data'])\n",
    "for dict in digital_master_res:\n",
    "    digital_master_data.append(dict['data'])\n",
    "for dict in digital_model_res:\n",
    "    digital_model_data.append(dict['data'])\n",
    "for dict in digital_repliica_res:\n",
    "    digital_repliica_data.append(dict['data'])\n",
    "for dict in digital_shadow_res:\n",
    "     if check(dict['meta']): digital_shadow_data.append(dict['data'])\n",
    "for dict in digital_thread_res:\n",
    "     if check(dict['meta']): digital_thread_data.append(dict['data'])\n",
    "for dict in information_mirroring_res:\n",
    "     if check(dict['meta']): information_mirroring_data.append(dict['data'])\n",
    "for dict in product_agent_res:\n",
    "     if check(dict['meta']):product_agent_data.append(dict['data'])\n",
    "for dict in product_avatar_res:\n",
    "     if check(dict['meta']):product_avatar_data.append(dict['data'])\n",
    "for dict in product_shadow_res:\n",
    "     if check(dict['meta']):product_shadow_data.append(dict['data'])\n",
    "for dict in virtual_twin_res:\n",
    "     if check(dict['meta']):virtual_twin_data.append(dict['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "908"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digital_twin_tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "data.append(digital_twin_tweets_data)\n",
    "data.append(cyber_twin_tweets_data)\n",
    "data.append(device_shadow_data)\n",
    "data.append(digital_counterpart_data)\n",
    "data.append(digital_master_data)\n",
    "data.append(digital_model_data)\n",
    "data.append(digital_repliica_data)\n",
    "data.append(digital_shadow_data)\n",
    "data.append(digital_thread_data)\n",
    "data.append(information_mirroring_data)\n",
    "data.append(product_agent_data)\n",
    "data.append(product_avatar_data)\n",
    "data.append(product_shadow_data)\n",
    "data.append(virtual_twin_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "908"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRes = [] #list of response data\n",
    "allRes.append(digital_twin_tweets_res)\n",
    "allRes.append(cyber_twin_tweets_res)\n",
    "allRes.append(device_shadow_res)\n",
    "allRes.append(digital_counterpart_res)\n",
    "allRes.append(digital_master_res)\n",
    "allRes.append(digital_model_res)\n",
    "allRes.append(digital_repliica_res)\n",
    "allRes.append(digital_shadow_res)\n",
    "allRes.append(digital_thread_res)\n",
    "allRes.append(information_mirroring_res)\n",
    "allRes.append(product_agent_res)\n",
    "allRes.append(product_avatar_res)\n",
    "allRes.append(product_shadow_res)\n",
    "allRes.append(virtual_twin_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "908"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digital_twin_tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_twin_tweets_df = pd.DataFrame(digital_twin_tweets_data[0])\n",
    "#cyber_twin_tweets_df = pd.DataFrame(cyber_twin_tweets_data[0])\n",
    "device_shadow_df = pd.DataFrame(device_shadow_data[0])\n",
    "digital_counterpart_df = pd.DataFrame(digital_counterpart_data[0])\n",
    "digital_master_df = pd.DataFrame(digital_master_data[0])\n",
    "digital_model_df = pd.DataFrame(digital_model_data[0])\n",
    "digital_repliica_df = pd.DataFrame(digital_repliica_data[0])\n",
    "digital_shadow_df = pd.DataFrame(digital_shadow_data[0])\n",
    "digital_thread_df = pd.DataFrame(digital_thread_data[0])\n",
    "information_mirroring_df = pd.DataFrame(information_mirroring_data[0])\n",
    "product_agent_df = pd.DataFrame(product_agent_data[0])\n",
    "product_avatar_df = pd.DataFrame(product_avatar_data[0])\n",
    "product_shadow_df = pd.DataFrame(product_shadow_data[0])\n",
    "virtual_twin_df = pd.DataFrame(virtual_twin_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in range(1,len(digital_twin_tweets_data)):\n",
    "    digital_twin_tweets_df = digital_twin_tweets_df.append(pd.DataFrame(digital_twin_tweets_data[obj]))\n",
    "for obj in range(1,len(device_shadow_data)):\n",
    "    device_shadow_df = device_shadow_df.append(pd.DataFrame(device_shadow_data[obj]))\n",
    "for obj in range(1,len(digital_counterpart_data)):\n",
    "    digital_counterpart_df = digital_counterpart_df.append(pd.DataFrame(digital_counterpart_data[obj]))\n",
    "for obj in range(1,len(digital_master_data)):\n",
    "    digital_master_df = digital_master_df.append(pd.DataFrame(digital_master_data[obj]))\n",
    "for obj in range(1,len(digital_model_data)):\n",
    "    digital_model_df = digital_model_df.append(pd.DataFrame(digital_model_data[obj]))\n",
    "for obj in range(1,len(digital_repliica_data)):\n",
    "    digital_repliica_df = digital_repliica_df.append(pd.DataFrame(digital_repliica_data[obj]))\n",
    "for obj in range(1,len(digital_shadow_data)):\n",
    "    digital_shadow_df = digital_shadow_df.append(pd.DataFrame(digital_shadow_data[obj]))\n",
    "for obj in range(1,len(digital_thread_data)):\n",
    "    digital_thread_df = digital_thread_df.append(pd.DataFrame(digital_thread_data[obj]))\n",
    "for obj in range(1,len(information_mirroring_data)):\n",
    "    information_mirroring_df = information_mirroring_df.append(pd.DataFrame(information_mirroring_data[obj]))\n",
    "for obj in range(1,len(product_agent_data)):\n",
    "    product_agent_df = product_agent_df.append(pd.DataFrame(product_agent_data[obj]))\n",
    "for obj in range(1,len(product_avatar_data)):\n",
    "    product_avatar_df = product_avatar_df.append(pd.DataFrame(product_avatar_data[obj]))\n",
    "for obj in range(1,len(product_shadow_data)):\n",
    "    product_shadow_df = product_shadow_df.append(pd.DataFrame(product_shadow_data[obj]))\n",
    "for obj in range(1,len(virtual_twin_data)):\n",
    "    virtual_twin_df = virtual_twin_df.append(pd.DataFrame(virtual_twin_data[obj]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfDataFrames = []\n",
    "listOfDataFrames.append(digital_twin_tweets_df)\n",
    "#listOfDataFrames.append(cyber_twin_tweets_res)\n",
    "listOfDataFrames.append(device_shadow_df)\n",
    "listOfDataFrames.append(digital_counterpart_df)\n",
    "listOfDataFrames.append(digital_master_df)\n",
    "listOfDataFrames.append(digital_model_df)\n",
    "listOfDataFrames.append(digital_repliica_df)\n",
    "listOfDataFrames.append(digital_shadow_df)\n",
    "listOfDataFrames.append(digital_thread_df)\n",
    "listOfDataFrames.append(information_mirroring_df)\n",
    "listOfDataFrames.append(product_agent_df)\n",
    "listOfDataFrames.append(product_avatar_df)\n",
    "listOfDataFrames.append(product_shadow_df)\n",
    "listOfDataFrames.append(virtual_twin_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "for DataFrame in listOfDataFrames:\n",
    "    DataFrame.to_pickle(str(x)+'.pkl')\n",
    "    x = x+1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in listOfDataFrames:\n",
    "    df = df[['lang','author_id','source','text', 'created_at']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isRT(text):\n",
    "        if text.startswith(\"RT\"): return \"True\"\n",
    "        else: return \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in listOfDataFrames:\n",
    "    df['is RT'] = df['text'].map(isRT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in listOfDataFrames:\n",
    "    df = df[df['is RT']=='False']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(431406, 18)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(963, 17)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(6192, 17)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(50407, 17)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(70027, 18)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(16963, 18)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(37913, 18)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(209043, 17)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(1, 11)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(5361, 17)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(2961, 17)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(10016, 17)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(10780, 18)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "for df in listOfDataFrames:\n",
    "    print(df.shape)\n",
    "    print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>public_metrics</th>\n",
       "      <th>text</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>created_at</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>entities</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>referenced_tweets</th>\n",
       "      <th>geo</th>\n",
       "      <th>attachments</th>\n",
       "      <th>context_annotations</th>\n",
       "      <th>withheld</th>\n",
       "      <th>is RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>755587</td>\n",
       "      <td>en</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>Glomming it!: I’m experimenting with glomming ...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>False</td>\n",
       "      <td>2007-12-21T12:55:47.000Z</td>\n",
       "      <td>521013662</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>521013662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15893823</td>\n",
       "      <td>en</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>[AUDIO Podcast] Insight Sunday 28 December: Th...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>False</td>\n",
       "      <td>2008-12-27T20:53:44.000Z</td>\n",
       "      <td>1081285947</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>1081285947</td>\n",
       "      <td>{'annotations': [{'start': 64, 'end': 73, 'pro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5813462</td>\n",
       "      <td>en</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>Reading about our digital shadow (rather than ...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>False</td>\n",
       "      <td>2008-12-16T14:40:28.000Z</td>\n",
       "      <td>1060683664</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>1060683664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17240275</td>\n",
       "      <td>en</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>Putting together the best ever EDD Showcase fo...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>False</td>\n",
       "      <td>2008-12-09T14:29:33.000Z</td>\n",
       "      <td>1047098684</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>1047098684</td>\n",
       "      <td>{'annotations': [{'start': 31, 'end': 66, 'pro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17157659</td>\n",
       "      <td>en</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>Putting together the best ever EDD Showcase fo...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>False</td>\n",
       "      <td>2008-12-09T14:29:05.000Z</td>\n",
       "      <td>1047097977</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>1047097977</td>\n",
       "      <td>{'annotations': [{'start': 31, 'end': 66, 'pro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1039121278936989697</td>\n",
       "      <td>en</td>\n",
       "      <td>{'retweet_count': 5, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>RT @AiThority: Harrison Van Riper, Research An...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-01-02T11:12:59.000Z</td>\n",
       "      <td>1212693263490043904</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1212693263490043904</td>\n",
       "      <td>{'mentions': [{'start': 3, 'end': 13, 'usernam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1206912270254497...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>953686343825096705</td>\n",
       "      <td>en</td>\n",
       "      <td>{'retweet_count': 1, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>RT @Kabuto_003: Who are watching our digital D...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-01-01T17:52:52.000Z</td>\n",
       "      <td>1212431511267332096</td>\n",
       "      <td>Quicker Zest 5</td>\n",
       "      <td>1212431511267332096</td>\n",
       "      <td>{'mentions': [{'start': 3, 'end': 14, 'usernam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1212410496537780...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'domain': {'id': '65', 'name': 'Interests an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20458706</td>\n",
       "      <td>en</td>\n",
       "      <td>{'retweet_count': 0, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>@marklevinshow would like to hear more on the ...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-01-01T17:43:22.000Z</td>\n",
       "      <td>1212097015594856454</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1212429120891580416</td>\n",
       "      <td>{'mentions': [{'start': 0, 'end': 14, 'usernam...</td>\n",
       "      <td>38495835</td>\n",
       "      <td>[{'type': 'replied_to', 'id': '121209701559485...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'domain': {'id': '10', 'name': 'Person', 'de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1136030202318991360</td>\n",
       "      <td>en</td>\n",
       "      <td>{'retweet_count': 1, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>Who are watching our digital DNA? Who are anal...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-01-01T16:29:22.000Z</td>\n",
       "      <td>1212410496537780225</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1212410496537780225</td>\n",
       "      <td>{'hashtags': [{'start': 72, 'end': 84, 'tag': ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'domain': {'id': '65', 'name': 'Interests an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>143897450</td>\n",
       "      <td>en</td>\n",
       "      <td>{'retweet_count': 5, 'reply_count': 0, 'like_c...</td>\n",
       "      <td>RT @AiThority: Harrison Van Riper, Research An...</td>\n",
       "      <td>everyone</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-01-01T04:06:14.000Z</td>\n",
       "      <td>1212223480944570368</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1212223480944570368</td>\n",
       "      <td>{'mentions': [{'start': 3, 'end': 13, 'usernam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'type': 'retweeted', 'id': '1206912270254497...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37913 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              author_id lang  \\\n",
       "0                755587   en   \n",
       "0              15893823   en   \n",
       "1               5813462   en   \n",
       "2              17240275   en   \n",
       "3              17157659   en   \n",
       "..                  ...  ...   \n",
       "10  1039121278936989697   en   \n",
       "11   953686343825096705   en   \n",
       "12             20458706   en   \n",
       "13  1136030202318991360   en   \n",
       "14            143897450   en   \n",
       "\n",
       "                                       public_metrics  \\\n",
       "0   {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "0   {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "1   {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "2   {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "3   {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "..                                                ...   \n",
       "10  {'retweet_count': 5, 'reply_count': 0, 'like_c...   \n",
       "11  {'retweet_count': 1, 'reply_count': 0, 'like_c...   \n",
       "12  {'retweet_count': 0, 'reply_count': 0, 'like_c...   \n",
       "13  {'retweet_count': 1, 'reply_count': 0, 'like_c...   \n",
       "14  {'retweet_count': 5, 'reply_count': 0, 'like_c...   \n",
       "\n",
       "                                                 text reply_settings  \\\n",
       "0   Glomming it!: I’m experimenting with glomming ...       everyone   \n",
       "0   [AUDIO Podcast] Insight Sunday 28 December: Th...       everyone   \n",
       "1   Reading about our digital shadow (rather than ...       everyone   \n",
       "2   Putting together the best ever EDD Showcase fo...       everyone   \n",
       "3   Putting together the best ever EDD Showcase fo...       everyone   \n",
       "..                                                ...            ...   \n",
       "10  RT @AiThority: Harrison Van Riper, Research An...       everyone   \n",
       "11  RT @Kabuto_003: Who are watching our digital D...       everyone   \n",
       "12  @marklevinshow would like to hear more on the ...       everyone   \n",
       "13  Who are watching our digital DNA? Who are anal...       everyone   \n",
       "14  RT @AiThority: Harrison Van Riper, Research An...       everyone   \n",
       "\n",
       "    possibly_sensitive                created_at      conversation_id  \\\n",
       "0                False  2007-12-21T12:55:47.000Z            521013662   \n",
       "0                False  2008-12-27T20:53:44.000Z           1081285947   \n",
       "1                False  2008-12-16T14:40:28.000Z           1060683664   \n",
       "2                False  2008-12-09T14:29:33.000Z           1047098684   \n",
       "3                False  2008-12-09T14:29:05.000Z           1047097977   \n",
       "..                 ...                       ...                  ...   \n",
       "10               False  2020-01-02T11:12:59.000Z  1212693263490043904   \n",
       "11               False  2020-01-01T17:52:52.000Z  1212431511267332096   \n",
       "12               False  2020-01-01T17:43:22.000Z  1212097015594856454   \n",
       "13               False  2020-01-01T16:29:22.000Z  1212410496537780225   \n",
       "14               False  2020-01-01T04:06:14.000Z  1212223480944570368   \n",
       "\n",
       "                source                   id  \\\n",
       "0   Twitter Web Client            521013662   \n",
       "0   Twitter Web Client           1081285947   \n",
       "1   Twitter Web Client           1060683664   \n",
       "2   Twitter Web Client           1047098684   \n",
       "3   Twitter Web Client           1047097977   \n",
       "..                 ...                  ...   \n",
       "10     Twitter Web App  1212693263490043904   \n",
       "11      Quicker Zest 5  1212431511267332096   \n",
       "12  Twitter for iPhone  1212429120891580416   \n",
       "13     Twitter Web App  1212410496537780225   \n",
       "14  Twitter for iPhone  1212223480944570368   \n",
       "\n",
       "                                             entities in_reply_to_user_id  \\\n",
       "0                                                 NaN                 NaN   \n",
       "0   {'annotations': [{'start': 64, 'end': 73, 'pro...                 NaN   \n",
       "1                                                 NaN                 NaN   \n",
       "2   {'annotations': [{'start': 31, 'end': 66, 'pro...                 NaN   \n",
       "3   {'annotations': [{'start': 31, 'end': 66, 'pro...                 NaN   \n",
       "..                                                ...                 ...   \n",
       "10  {'mentions': [{'start': 3, 'end': 13, 'usernam...                 NaN   \n",
       "11  {'mentions': [{'start': 3, 'end': 14, 'usernam...                 NaN   \n",
       "12  {'mentions': [{'start': 0, 'end': 14, 'usernam...            38495835   \n",
       "13  {'hashtags': [{'start': 72, 'end': 84, 'tag': ...                 NaN   \n",
       "14  {'mentions': [{'start': 3, 'end': 13, 'usernam...                 NaN   \n",
       "\n",
       "                                    referenced_tweets  geo attachments  \\\n",
       "0                                                 NaN  NaN         NaN   \n",
       "0                                                 NaN  NaN         NaN   \n",
       "1                                                 NaN  NaN         NaN   \n",
       "2                                                 NaN  NaN         NaN   \n",
       "3                                                 NaN  NaN         NaN   \n",
       "..                                                ...  ...         ...   \n",
       "10  [{'type': 'retweeted', 'id': '1206912270254497...  NaN         NaN   \n",
       "11  [{'type': 'retweeted', 'id': '1212410496537780...  NaN         NaN   \n",
       "12  [{'type': 'replied_to', 'id': '121209701559485...  NaN         NaN   \n",
       "13                                                NaN  NaN         NaN   \n",
       "14  [{'type': 'retweeted', 'id': '1206912270254497...  NaN         NaN   \n",
       "\n",
       "                                  context_annotations withheld  is RT  \n",
       "0                                                 NaN      NaN  False  \n",
       "0                                                 NaN      NaN  False  \n",
       "1                                                 NaN      NaN  False  \n",
       "2                                                 NaN      NaN  False  \n",
       "3                                                 NaN      NaN  False  \n",
       "..                                                ...      ...    ...  \n",
       "10                                                NaN      NaN   True  \n",
       "11  [{'domain': {'id': '65', 'name': 'Interests an...      NaN   True  \n",
       "12  [{'domain': {'id': '10', 'name': 'Person', 'de...      NaN  False  \n",
       "13  [{'domain': {'id': '65', 'name': 'Interests an...      NaN  False  \n",
       "14                                                NaN      NaN   True  \n",
       "\n",
       "[37913 rows x 18 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfDataFrames[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,12):\n",
    "    listOfDataFrames[i] = listOfDataFrames[i][['lang','author_id','source','text', 'created_at']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfDataFrames[0]['is RT'] = listOfDataFrames[0]['text'].map(isRT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>author_id</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>is RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>47973</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>From virtual Moscow to virtual Twin Towers NYC...</td>\n",
       "      <td>2007-09-04T14:31:46.000Z</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>2735591</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>My Virtual Twin, in Progress: I've been hard a...</td>\n",
       "      <td>2007-04-17T17:10:03.000Z</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>14335125</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>I am delaying doing my first Moodle audit to c...</td>\n",
       "      <td>2008-11-28T12:14:38.000Z</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>14791560</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>Check out these Facebook photos -- I think Pas...</td>\n",
       "      <td>2008-11-25T23:07:36.000Z</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>14447318</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>@barbaravey thanks. Alas, there was no room in...</td>\n",
       "      <td>2008-09-30T23:06:10.000Z</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang author_id              source  \\\n",
       "0   en     47973  Twitter Web Client   \n",
       "1   en   2735591  Twitter Web Client   \n",
       "0   en  14335125  Twitter Web Client   \n",
       "1   en  14791560  Twitter Web Client   \n",
       "2   en  14447318  Twitter Web Client   \n",
       "\n",
       "                                                text  \\\n",
       "0  From virtual Moscow to virtual Twin Towers NYC...   \n",
       "1  My Virtual Twin, in Progress: I've been hard a...   \n",
       "0  I am delaying doing my first Moodle audit to c...   \n",
       "1  Check out these Facebook photos -- I think Pas...   \n",
       "2  @barbaravey thanks. Alas, there was no room in...   \n",
       "\n",
       "                 created_at  is RT  \n",
       "0  2007-09-04T14:31:46.000Z  False  \n",
       "1  2007-04-17T17:10:03.000Z  False  \n",
       "0  2008-11-28T12:14:38.000Z  False  \n",
       "1  2008-11-25T23:07:36.000Z  False  \n",
       "2  2008-09-30T23:06:10.000Z  False  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfDataFrames[12].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,12):\n",
    "    listOfDataFrames[i]['is RT'] = listOfDataFrames[i]['text'].map(isRT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfDataFrames[12] = listOfDataFrames[12][['lang','author_id','source','text', 'created_at']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>author_id</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>is RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>47973</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>From virtual Moscow to virtual Twin Towers NYC...</td>\n",
       "      <td>2007-09-04T14:31:46.000Z</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>2735591</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>My Virtual Twin, in Progress: I've been hard a...</td>\n",
       "      <td>2007-04-17T17:10:03.000Z</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>14335125</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>I am delaying doing my first Moodle audit to c...</td>\n",
       "      <td>2008-11-28T12:14:38.000Z</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>14791560</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>Check out these Facebook photos -- I think Pas...</td>\n",
       "      <td>2008-11-25T23:07:36.000Z</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>14447318</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>@barbaravey thanks. Alas, there was no room in...</td>\n",
       "      <td>2008-09-30T23:06:10.000Z</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>en</td>\n",
       "      <td>71964488</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>@leashless Happy birthday to you! \\nReading ht...</td>\n",
       "      <td>2020-01-07T05:12:39.000Z</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>en</td>\n",
       "      <td>2901267208</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>In a way we all have a virtual twin, we tend t...</td>\n",
       "      <td>2020-01-06T22:11:58.000Z</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>en</td>\n",
       "      <td>806691055575805952</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>@brianwithani Oh nice! Green is an awesome col...</td>\n",
       "      <td>2020-01-03T23:33:02.000Z</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>en</td>\n",
       "      <td>3096227312</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>@glums90 how are you, my virtual twin?</td>\n",
       "      <td>2020-01-03T14:26:56.000Z</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>en</td>\n",
       "      <td>1169447697050480640</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>RT @drfootleg: 1) My #PiWars 2019 robot. My fi...</td>\n",
       "      <td>2020-01-01T04:14:16.000Z</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10780 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    lang            author_id               source  \\\n",
       "0     en                47973   Twitter Web Client   \n",
       "1     en              2735591   Twitter Web Client   \n",
       "0     en             14335125   Twitter Web Client   \n",
       "1     en             14791560   Twitter Web Client   \n",
       "2     en             14447318   Twitter Web Client   \n",
       "..   ...                  ...                  ...   \n",
       "392   en             71964488      Twitter Web App   \n",
       "393   en           2901267208  Twitter for Android   \n",
       "394   en   806691055575805952   Twitter for iPhone   \n",
       "395   en           3096227312  Twitter for Android   \n",
       "396   en  1169447697050480640  Twitter for Android   \n",
       "\n",
       "                                                  text  \\\n",
       "0    From virtual Moscow to virtual Twin Towers NYC...   \n",
       "1    My Virtual Twin, in Progress: I've been hard a...   \n",
       "0    I am delaying doing my first Moodle audit to c...   \n",
       "1    Check out these Facebook photos -- I think Pas...   \n",
       "2    @barbaravey thanks. Alas, there was no room in...   \n",
       "..                                                 ...   \n",
       "392  @leashless Happy birthday to you! \\nReading ht...   \n",
       "393  In a way we all have a virtual twin, we tend t...   \n",
       "394  @brianwithani Oh nice! Green is an awesome col...   \n",
       "395             @glums90 how are you, my virtual twin?   \n",
       "396  RT @drfootleg: 1) My #PiWars 2019 robot. My fi...   \n",
       "\n",
       "                   created_at  is RT  \n",
       "0    2007-09-04T14:31:46.000Z  False  \n",
       "1    2007-04-17T17:10:03.000Z  False  \n",
       "0    2008-11-28T12:14:38.000Z  False  \n",
       "1    2008-11-25T23:07:36.000Z  False  \n",
       "2    2008-09-30T23:06:10.000Z  False  \n",
       "..                        ...    ...  \n",
       "392  2020-01-07T05:12:39.000Z  False  \n",
       "393  2020-01-06T22:11:58.000Z  False  \n",
       "394  2020-01-03T23:33:02.000Z  False  \n",
       "395  2020-01-03T14:26:56.000Z  False  \n",
       "396  2020-01-01T04:14:16.000Z   True  \n",
       "\n",
       "[10780 rows x 6 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "listOfDataFrames[12]['is RT'] = listOfDataFrames[12]['text'].map(isRT)\n",
    "listOfDataFrames[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,12):\n",
    "    listOfDataFrames[i] = listOfDataFrames[i][listOfDataFrames[i]['is RT']==\"False\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193365\n",
      "518\n",
      "3940\n",
      "33829\n",
      "34619\n",
      "7697\n",
      "22022\n",
      "188852\n",
      "1\n",
      "4601\n",
      "1510\n",
      "6775\n",
      "10780\n",
      "508509\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for obj in listOfDataFrames:\n",
    "    print(len(obj))\n",
    "    count = count + len(obj)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,12):\n",
    "    listOfDataFrames[i] = listOfDataFrames[i][(listOfDataFrames[i]['lang'] == \"en\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,12):    \n",
    "    listOfDataFrames[i] = listOfDataFrames[i].drop(['is RT'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,12):\n",
    "    listOfDataFrames[i]['hashtag'] = listOfDataFrames[i]['text'].apply(lambda x: re.findall(r\"#(\\w+)\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,12):\n",
    "    listOfDataFrames[i] = listOfDataFrames[i].drop(columns=['created_at', 'lang'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_twin_tweets_text = digital_twin_tweets_df['text'].tolist()\n",
    "#cyber_twin_tweets_text = cyber[]\n",
    "device_shadow_text = device_shadow_df['text'].tolist()\n",
    "digital_counterpart_text = digital_counterpart_df['text'].tolist()\n",
    "digital_master_text = digital_master_df['text'].tolist()\n",
    "digital_model_text = digital_model_df['text'].tolist()\n",
    "digital_repliica_text = digital_repliica_df['text'].tolist()\n",
    "digital_shadow_text = digital_shadow_df['text'].tolist()\n",
    "digital_thread_text = digital_thread_df['text'].tolist()\n",
    "information_mirroring_text = information_mirroring_df['text'].tolist()\n",
    "product_agent_text = product_agent_df['text'].tolist()\n",
    "product_avatar_text = product_avatar_df['text'].tolist()\n",
    "product_shadow_text = product_shadow_df['text'].tolist()\n",
    "virtual_twin_text = virtual_twin_df['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(digital_twin_tweets_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,v in enumerate(digital_twin_tweets_text):\n",
    "    digital_twin_tweets_text[i] = p.clean(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,v in enumerate(device_shadow_text):\n",
    "    device_shadow_text[i] = p.clean(v)\n",
    "for i,v in enumerate(digital_counterpart_text):\n",
    "    digital_counterpart_text[i] = p.clean(v)\n",
    "for i,v in enumerate(digital_master_text):\n",
    "    digital_master_text[i] = p.clean(v)\n",
    "for i,v in enumerate(digital_model_text):\n",
    "    digital_model_text[i] = p.clean(v)\n",
    "    \n",
    "for i,v in enumerate(digital_repliica_text):\n",
    "    digital_repliica_text[i] = p.clean(v)\n",
    "for i,v in enumerate(digital_shadow_text):\n",
    "    digital_shadow_text[i] = p.clean(v)\n",
    "for i,v in enumerate(digital_thread_text):\n",
    "    digital_thread_text[i] = p.clean(v)\n",
    "    \n",
    "for i,v in enumerate(information_mirroring_text):\n",
    "    information_mirroring_text[i] = p.clean(v)\n",
    "for i,v in enumerate(product_agent_text):\n",
    "    product_agent_text[i] = p.clean(v)\n",
    "for i,v in enumerate(product_avatar_text):\n",
    "    product_avatar_text[i] = p.clean(v)\n",
    "for i,v in enumerate(product_shadow_text):\n",
    "    product_shadow_text[i] = p.clean(v)\n",
    "for i,v in enumerate(virtual_twin_text):\n",
    "    virtual_twin_text[i] = p.clean(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_cleaner(text):\n",
    "    \n",
    "    text = text.encode(encoding=\"ascii\", errors=\"ignore\")\n",
    "    text = text.decode() # removing unicode from the text \n",
    "    \n",
    "    text = p.clean(text)\n",
    "    \n",
    "    text = text.lower() #lowering all the text\n",
    "    \n",
    "    punct = set(string.punctuation)\n",
    "    text = \"\".join([ch for ch in text if ch not in punct]) #remove punctation\n",
    "    \n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words]) #remove stopwords\n",
    "    # try out stemming and lemmatization\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bajaj Auto's DTS-Si engine offers km/l: Bajaj on Thursday launched 'Digital Twin Spark-Swirl inducti..\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digital_twin_tweets_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in range(0, len(digital_twin_tweets_text)):\n",
    "    digital_twin_tweets_text[obj] = txt_cleaner(digital_twin_tweets_text[obj])\n",
    "for obj in range(0, len(device_shadow_text)):\n",
    "    device_shadow_text[obj] = txt_cleaner(device_shadow_text[obj])\n",
    "for obj in range(0, len(digital_counterpart_text)):\n",
    "    digital_counterpart_text[obj] = txt_cleaner(digital_counterpart_text[obj])\n",
    "for obj in range(0, len(digital_master_text)):\n",
    "    digital_master_text[obj] = txt_cleaner(digital_master_text[obj])\n",
    "for obj in range(0, len(digital_model_text)):\n",
    "    digital_model_text[obj] = txt_cleaner(digital_model_text[obj])\n",
    "for obj in range(0, len(digital_repliica_text)):\n",
    "    digital_repliica_text[obj] = txt_cleaner(digital_repliica_text[obj])\n",
    "for obj in range(0, len(digital_shadow_text)):\n",
    "    digital_shadow_text[obj] = txt_cleaner(digital_shadow_text[obj])\n",
    "for obj in range(0, len(digital_thread_text)):\n",
    "    digital_thread_text[obj] = txt_cleaner(digital_thread_text[obj])\n",
    "for obj in range(0, len(information_mirroring_text)):\n",
    "    information_mirroring_text[obj] = txt_cleaner(information_mirroring_text[obj])\n",
    "for obj in range(0, len(product_agent_text)):\n",
    "    product_agent_text[obj] = txt_cleaner(product_agent_text[obj])\n",
    "for obj in range(0, len(product_avatar_text)):\n",
    "    product_avatar_text[obj] = txt_cleaner(product_avatar_text[obj])\n",
    "for obj in range(0, len(product_shadow_text)):\n",
    "    product_shadow_text[obj] = txt_cleaner(product_shadow_text[obj])\n",
    "for obj in range(0, len(virtual_twin_text)):\n",
    "    virtual_twin_text[obj] = txt_cleaner(virtual_twin_text[obj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bajaj autos dtssi engine offers kml bajaj thursday launched digital twin sparkswirl inducti'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digital_twin_tweets_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "digital_twin_tweets_df['text'] = pd.Series(digital_twin_tweets_text)\n",
    "#cyber_twin_tweets_df = pd.DataFrame(cyber_twin_tweets_data[0])\n",
    "device_shadow_df['text'] = pd.Series(device_shadow_text)\n",
    "digital_counterpart_df['text'] = pd.Series(digital_counterpart_text)\n",
    "digital_master_df['text'] = pd.Series(digital_master_text)\n",
    "digital_model_df['text'] = pd.Series(digital_model_text)\n",
    "digital_repliica_df['text'] = pd.Series(digital_repliica_text)\n",
    "digital_shadow_df['text'] = pd.Series(digital_shadow_text)\n",
    "digital_thread_df['text'] = pd.Series(digital_thread_text)\n",
    "information_mirroring_df['text'] = pd.Series(information_mirroring_text)\n",
    "product_agent_df['text'] = pd.Series(product_agent_text)\n",
    "product_avatar_df['text'] = pd.Series(product_avatar_text)\n",
    "product_shadow_df['text'] = pd.Series(product_shadow_text)\n",
    "virtual_twin_df['text'] = pd.Series(virtual_twin_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-9c36b80d3a00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install --no-binary :all:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_blobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhdbscan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hdbscan/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhdbscan_\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHDBSCAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdbscan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrobust_single_linkage_\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRobustSingleLinkage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrobust_single_linkage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvalidity\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidity_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m from .prediction import (approximate_predict,\n\u001b[1;32m      5\u001b[0m                          \u001b[0mmembership_vector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/hdbscan/hdbscan_.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m from ._hdbscan_linkage import (single_linkage,\n\u001b[0m\u001b[1;32m     22\u001b[0m                                \u001b[0mmst_linkage_core\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                \u001b[0mmst_linkage_core_vector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mhdbscan/_hdbscan_linkage.pyx\u001b[0m in \u001b[0;36minit hdbscan._hdbscan_linkage\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.ndarray size changed, may indicate binary incompatibility. Expected 88 from C header, got 80 from PyObject"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "!pip install --no-binary :all:\n",
    "from sklearn.datasets import make_blobs\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hdbscan' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-206a97a2b3ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_blobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclusterer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhdbscan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHDBSCAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_cluster_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcluster_labels_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclusterer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigital_counterpart_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hdbscan' is not defined"
     ]
    }
   ],
   "source": [
    "data, _ = make_blobs(1000)\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=10)\n",
    "cluster_labels_ = clusterer.fit_predict(digital_counterpart_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
